---
title: LED经典论文
description: LED三篇经典论文笔记
tags:
 - LED
---

LED三篇经典论文笔记。

<br />

<!--more-->

想法

1. 利用用户重复发言
2. @, hash tag, emoji，usr（用户会不会有重复发言）
8. 加入地图信息
9. 预测下一刻会发生什么
10. attention图
12. 预测数量特征变成预测语义特征




## 论文搜索

* KDD(18) SIGIR(18) SIGSPATIAL(18) WWW(18) ICDM(18) ICDE(18) AAAI(18) IJCAI ICML NIPS ACL VLDB ICDE SIGMOD ACM-MM ICCV CVPR
* chaozhang的个人主页 
* global event detection
* geoburst引用



---



## 传统

### Geoburst

##### 内容

1. seek:

   * 根据空间和语义(关键词转移概率)相似度定义provit

   * 按照provit聚类成cluster

2. rank

   * 用cluster构成时间线，越近的事件粒度越小
   * 利用时间线事件的均值、标准差求出时、空突发度，再排序

3. online

   * 通过集合减法表示事件的变化
   * 只重新计算被改动点影响的provit

##### 评价

* 时间线的想法值得参考
* 更新算法好
* 只用关键词算语义相关不大行



### EvenTweet

##### 内容

1. seek
   * (时间框内)时间关键词提取, 用历史的平均值/方差(可以利用无地理标签的tweet)
   * 空间关键词提取, 提取出现范围小,集中的

##### 评价

----





## 半传统

### TrioVecEvent

#### 内容

1. Embedding

   * 时空分块，CBOW，点积得相似度，Soft，交叉熵
2. Seek
   * 贝叶斯混合模型(TrioVec)
   * 增量更新
3. Classify
   * 提取出时、空、语义、突发性等特征送到MLP

#### 评价

* embed改进？
* 最后送到mlp不错
* 获得三个embedding



### CrossMap

#### 内容

​    作者主要解决GTSM数据的两个挑战：1. 时空差异性。可能一场篮球赛会有人在不同地点，不同时间发tweet，为了避免分开考虑他们而造成时空和联系的稀疏性，需要找到一种表示方法。而通过观察，作者发现人们行为总在一定区间和时间范围内快速增长，因此提出了hotspot来归纳这一区域和时间的某个行为。2. 要抓住时间，地点，文本之间的联系。之前的模型假设了一些不符合实际的数据分布，例如高斯，且计算量大，又慢又菜。所以提出了一个直接的生成式模型，结合了record embed和graph embed。

1. 找hotspot

    定义：用了kernel找出了一个collection中最集中的地点和时间，分别是地点和时间的hotspot。  用这个kernel好处是没有预先定义数据结构，可以自由发挥。  

    寻找：每次都往区域内kernel均值最大的地方走，直到没有。感觉上是走到了最密集的地方。

2. joint embed

    先用gauss定义了空间和时间的kernel strength。

    RecordEmbed：给定一个record中的两个元素，预测第三个，loss：相似度的softmax。

    ​    定义相似度s：定义了三个元素的向量，都是kernel strenght占比再乘一个参数，取平均为h，再用乘    上一个参数

    GraphEmbed：

    ​    构建：时，空，文个node，对于共现来说有4个边（C_3^2），对于邻居来说有2个边：时-时，空-空。并把neighbour连起来，kernel strenghth作为权重。

    ​    学习：向量乘的softmax

---





## 深度学习

### DELLE（ResConvLSTM TweetCount）
#### 内容

1. seek
   
   ​    本篇文章的intuition在于，当有local event发生的时候，这个区块的tweet量会上升。因此可以通过现实tweet量和用历史数据推测出的tweet量作对比，得出当地是否有local event发生。
   
   ​    首先是通过Residual ConvLSTM（LTSM里加Conv）推测tweet量。
   
   ​    获得预测值Et之后，将预测值Et乘上可信度（可信度为这个地区所有时间下tweet预测值的标准差，也就是tweet量的波动情况）得到E't。
   
   ​    第二个intuition是，在图E‘t中，local event就像一个噪声。因此用Deep Image Prior去除噪声，获得差值 $ \Delta Et $ 。
   
   ​    满足 $ \langle {\Delta Et}(m, n) - \mu_{\Delta Et} \rangle \ge k_{\Delta Et} * \sigma_{\Delta Et} $ 的就是local event发生的cell(m, n)。
   
   ​    这里 $ \mu, \sigma $ 是图中所有cell的均值，方差，k是当前cell的阀值。这样刻画出了噪声程度相对于附近区域的差距，也排除了global event。
   
2. rank
   ​    找到了localtion以后，将这些地点按照时间突发性，空间突发性，主题一致性排序，选出top K。
	
	​    时间突发性TB：（实际tweet-该location历史预测的均值） / 该location历史预测的标准差
	
	​    空间突发性SB：关键词出现集中说明是event，稀疏说明是平常事件。该location中所有tweet关键词数 / 关键词在别的区域出现的次数的和。
	
	​    主题一致性TC：主题一致则像event，出现多topic几率小。用Tweet2Vec（字符级双向GRU）构建向量，用蜜汁方式得出了主题相似度TS。再构建一个图，边为TS，使用Pagerank排序得到topK个最有影响力的tweet。计算他们影响力之和/k方得到主题一致性。
	
	​    排序： 
	
	​    $ R_t(m, n) =  TB'_t(m, n) * SB'_t(m, n) * TC'_t(m, n) $
	
	​    $ TB'_t(m, n) = \frac {TB_t(m, n) - TB_t^{min}}{TB_t^{max} - TB_t^{min}} $

#### 评价

* ResConvLSTM好，但是只用过去信息*不能很好预测*，加attn？
* 去噪方法有点奇怪
* 空间突发性不好，例如着火，其他地区也会有


