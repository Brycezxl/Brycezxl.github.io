---
title: cs231n
description: cs231n
tags:
 - 新手村
 - CV
---

#### [YouTube](https://www.youtube.com/watch?v=DAOcjicFr1Y&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=9)
<br />

<!--more-->

***

## Lecture 5 CNN

### 卷积层

![卷积](/pictures/conv_sum.png)


### 池化层

![池化](/pictures/pooling.png)

### ReLU

![ReLU](/pictures/relu_ini.png)

ReLU变0后没有梯度→dead

通过初始化改善

***

## Lecture 6 Train NN I

### 选择激活函数

![ac](/pictures/choose_act.png)

### 预处理

对一般数据 $ \frac {x-mean}{std} $

对于图片:

![preprocess](/pictures/preprocess.png)

### 初始化权重

对于线性:

![weight1](/pictures/xavier.png)

对于非线性(ReLU):

![weight2](/pictures/he_ini.png)

更多论文:

![weight2](/pictures/ini_papers.png)

### Batch Norm

对每一层都norm,而非只有输入层

![batch](/pictures/batch_norm.png)

### Hyperparameters Optimization

根据Cost函数图像改进学习率:

![batch](/pictures/learning_rate.png)

Coarse to fine search:

![batch](/pictures/cross_validation.png)

![batch](/pictures/coarse_example.png)

先只根据几次epoch训练出来的数据,测试多个较大范围内随机取的超参,再根据acc缩小范围


也可以画图:

![batch](/pictures/hyper_layout.png)

***

## Lecture 7 Train NN II

### Fancier Optimization

Adam:

![batch](/pictures/adam.png)

集成了动量,adagrad(平衡各方向上的移动),加入bias防止第一步上天


Second-Order Opitimization

![batch](/pictures/second_order.png)

![batch](/pictures/second_order2.png)

**Choice:**

![batch](/pictures/back_choice.png)

### Regularization

dropout:

![batch](/pictures/inverted_dropout.png)

随机将一定比例神经元置0

普通dropout在train时不除以p,test时将神经元输出乘上比例

inverted dropout将这个过程再train里实现,加快test

*可以用lambda, batch norm(功能类似于dropout)*

### Transfer Learning

![batch](/pictures/cnn_transfer_learning.png)

***
