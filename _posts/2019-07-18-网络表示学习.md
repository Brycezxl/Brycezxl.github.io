---
title: NLR 网络表示学习（无监督）
categories:
 - LED
tags:
 - LED
 - 图神经网络
---

有关网络表示学习（Network Embedding Learning）的研究（无监督方向）的概括。

<!--more-->

## 想法

图的目标

1. 词-时间（晚餐）
2. 词-地点（机场）
3. 时间上词的关系（无关词突然出现，某些词因果关系）
4. 空间上词的关系（共现，邻域）

问题

1. 现有的ne方法是怎样的，有什么缺点
2. gnn的方法中有什么可以借鉴的
3. 如何加入文本信息
4. 时间，地区的划分方式如何改进
5. 通过图embed聚类
6. rank

想法

1. 结点根据长期中期短期分阶层
2. 用attention代替walk

---



## Random Walk

对图进行某种游走，并且通过生成的序列训练embed（例如word2vec）



### DeepWalk

DeepWalk: Online Learning of Social Representations

给出了图学习的范例：选择输入矩阵 -> 取样序列 -> 学习embed

结合embed与NLR，通过随机游走生成序列，把序列当作nlp中的上下文语义，对序列使用word2vec

拥有相似邻居的结点就会距离更近



### Node2Vec

继承了DeepWalk的思想，把他的随机游走进行了改进。

Random Walk只能捕捉长距离的结构关系，而此处想要捕捉短距离关系（结点的邻域）和长距离关系（远距离的相似的结点），结合了深度优先与广度优先。





---



## Edge Modeling



### LINE

Large-scale Information Network Embedding

让结点之间的一阶相似度与二阶相似度最小。

即让相邻的结点与拥有类似邻居的结点距离最近。



### GraphGAN

生成器：
     优化：一般是使相邻结点边的softmax最大，作者在此处改进了softmax。
     1.为了减少计算量，使用广度优先算法获得结点的树，作为softmax范围。
     2.普通的softmax并没有考虑图的结构，改进为如下，p为领域的softmax，考虑到了这条路上的概率。
     生成：使用广度优先算法生成树后，按照新softmax定义的概率进行随机游走，当下一步是父节点时停止（最远且够真）（why？？？？？？）。



判别器：判断生成器给出的两个结点是否存在边

 $ G(v\|v_c)=( \prod^m_{j=1} p_c(v_{r_j}\|v_{r_{j-1}}))* p_c(v_{m-1}\|v_{r_m}) $ 

评价

- softmax的改进使得越远影响越小，但是感觉递减的幅度太大了
- 为什么生成远处的点？
- 判别器可以参考hin2vec判别生成器生成的是否是两结点之间的点。
- 只考虑到了一阶相似度

---



## HIN



### HNE

Heterogeneous Network Embedding via Deep Architectures

将不同类型的顶点映射到相同维度的空间

对于图片用cnn+fc，对文本用fc，预测最大化右边的概率



### Metapath2Vec

metapath2vec: Scalable Representation Learning for Heterogeneous Networks

针对异构网络改进了deepwalk

异构网络中，随机游走会偏向那些连接多或者在一定区域内比较集中的点，至于为什么，详见`Pathsim: Meta path-based top-k similarity search in heterogeneous information networks`

因此设定好一个固定的游走类型（例如文章-作者-文章），按这个顺序进行游走，能更好抓住语义信息，例如文章和作者有关



### HIN2Vec

HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning

判断两个顶点间是否有某个meta关系，例如文章-作者-文章或文章-出版社-文章

-----



## Deep Learning

主要是使用autoencoder来对矩阵进行重新编码



### DNGR

使用更好的方法表示线性结构

之前使用的random walk有两个缺点：1. 采样序列的长度是固定的，这使得采样序列边缘的节点的上下文信息相对于中间的较难捕捉。2. 对于大型网络，无法很直接地确定一些超参数，例如游走长度和游走路数等。

此处使用random surfing（借鉴pagerank）构成PCO概率矩阵，再对概率矩阵进行PPMI，再送入denoising autoencoder (在原样本中增加噪声，再将加噪样本来还原成纯净样本) 进行重构

------



## Matrix

对临接矩阵进行花式操作



### GraRep

根据DeepWalk的想法，skip-gram模型其实就是用来量化两个节点的k阶关系，grarep学习了高阶相似度来提取全局信息。

先用skipgram学到k个临接矩阵的表示，再用SVD分解，最后结合起来



### GraphAttention

Watch Your Step: Learning Node Embeddings via Graph Attention

上面的方法都是对不同阶数的邻接矩阵人工设计参数

此处对不同阶数的临接矩阵进行attention，让网络自动学习

----



## Hybird

综合的方法



### HRAP

为了在大型图中掌握全局信息，对结点进行一步步单独边与星型折叠，然后从小图到大图对每一步折叠进行deepwalk或line训练

---

